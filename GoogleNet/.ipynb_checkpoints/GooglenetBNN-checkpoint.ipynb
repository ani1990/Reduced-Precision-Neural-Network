{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ2Mx1qVuXs9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D,Dropout, Dense, Input, concatenate,GlobalAveragePooling2D, AveragePooling2D,Flatten\n",
    "\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import larq as lq\n",
    "from quantized.layers import QuantConv2D,QuantDense\n",
    "from quantized.models import summary\n",
    "from quantized.math import binary_tanh as binary_ops\n",
    "from quantized.quantizers import DoReFaQuantizer,ste_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customized activation function\n",
    "def binary_tanh(x):\n",
    "    return binary_ops(x)\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-JG-iidumve"
   },
   "outputs": [],
   "source": [
    "#inception net basic module function to be used while creating network\n",
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1=QuantConv2D(filters_1x1, (1, 1),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(x)\n",
    "    \n",
    "    conv_3x3=QuantConv2D(filters_3x3_reduce, (1, 1),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(x)\n",
    "    conv_3x3=QuantConv2D(filters_3x3, (3, 3),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(conv_3x3)\n",
    "\n",
    "    conv_5x5=QuantConv2D(filters_5x5_reduce, (1, 1),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(x)\n",
    "\n",
    "    conv_5x5=QuantConv2D(filters_5x5, (5, 5),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj=QuantConv2D(filters_pool_proj, (1, 1),**kwargs,use_bias=bias_init, padding=\"same\",activation=binary_tanh)(pool_proj)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LBtIioMupJr"
   },
   "outputs": [],
   "source": [
    "kernel_init = keras.initializers.glorot_uniform()\n",
    "bias_init = keras.initializers.Constant(value=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Qx7qPiPur-b"
   },
   "outputs": [],
   "source": [
    "#creating layers of GoogleNet\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,MaxPooling2D\n",
    "input_layer = tf.keras.Input(shape=(227, 227, 3))\n",
    "np.random.seed(0)\n",
    "x=(QuantConv2D(64, (7, 7),strides=(2,2),\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=bias_init,padding='same',activation='relu')(input_layer))\n",
    "\n",
    "#x = QuantConv2D(64, (7, 7),strides=(2, 2),kernel_quantizer=\"ste_sign\",kernel_constraint=\"weight_clip\",use_bias=bias_init, padding=\"same\",activation='relu',name='conv_1_7x7/2')(input_layer)\n",
    "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "#x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = QuantConv2D(64, (1, 1),strides=(1, 1), padding=\"same\",activation=binary_tanh,name='conv_2a_3x3/1')(x)\n",
    "\n",
    "#x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = QuantConv2D(192, (3, 3),strides=(1, 1), padding=\"same\",activation=binary_tanh,name='conv_2b_3x3/1')(x)\n",
    "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=192,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=96,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_3b')\n",
    "\n",
    "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=192,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=208,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=48,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4a')\n",
    "\n",
    "\n",
    "x1 = tf.keras.layers.AvgPool2D((5, 5), strides=3)(x)\n",
    "#x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = QuantConv2D(128, (1, 1), padding=\"same\",activation=binary_tanh)(x1)\n",
    "x1 = tf.keras.layers.Flatten()(x1)\n",
    "x1 = Dense(1024, activation=binary_tanh)(x1)\n",
    "x1 = Dropout(0.7)(x1)\n",
    "x1 = Dense(2, activation='softmax', name='auxilliary_output_1')(x1)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=160,\n",
    "                     filters_3x3_reduce=112,\n",
    "                     filters_3x3=224,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4b')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=256,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4c')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=112,\n",
    "                     filters_3x3_reduce=144,\n",
    "                     filters_3x3=288,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4d')\n",
    "\n",
    "\n",
    "x2 = tf.keras.layers.AvgPool2D((5, 5), strides=3)(x)\n",
    "#x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = QuantConv2D(128, (1, 1), padding=\"same\",activation=binary_tanh)(x2)\n",
    "x2 = tf.keras.layers.Flatten()(x2)\n",
    "x2 = Dense(1024, activation=binary_tanh)(x2)\n",
    "x2 = Dropout(0.7)(x2)\n",
    "x2 = Dense(2, activation='softmax', name='auxilliary_output_2')(x2)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_4e')\n",
    "\n",
    "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=384,\n",
    "                     filters_3x3_reduce=192,\n",
    "                     filters_3x3=384,\n",
    "                     filters_5x5_reduce=48,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5b')\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(2, activation='softmax', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2pTTEgS2vACD",
    "outputId": "11665156-cb69-4d20-a469-2bd35f417bc8"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input_layer, x, name='inception_v1')\n",
    "#if you want to use full feature of googlenet use below command but this inflate number of parameters by twice and vey slow\n",
    "#model = Model(input_layer, [x,x1,x2], name='inception_v1') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4zmjFNxt0KoS",
    "outputId": "10096980-e5a2-4bd9-9cca-f38acd6558ac"
   },
   "outputs": [],
   "source": [
    "#loading and preprocessing data from dataset\n",
    "#please change path as per dataset in your system\n",
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=\"/training_set/training_set\",target_size=(227,227))\n",
    "trdata = ImageDataGenerator()\n",
    "testdata = trdata.flow_from_directory(directory=\"/test_set/test_set\",target_size=(227,227))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_n8MrrM50023"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qQHehglC0jhK",
    "outputId": "8f919d00-1331-480b-c7c5-56b1eec3543e"
   },
   "outputs": [],
   "source": [
    "#defining Earlystopping callback and saving the best model for future use\n",
    "checkpoint = ModelCheckpoint(\"googlenet_fp.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#training and validating train and validation data respectively\n",
    "hist = model.fit_generator(steps_per_epoch=2,generator=traindata, validation_data= testdata, \n",
    "                           validation_steps=10,epochs=150,callbacks=[checkpoint,early],shuffle=False,use_multiprocessing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_jKCop9_AcUP",
    "outputId": "69d94124-14db-4c67-fe0a-c8bb53cf1ad5"
   },
   "outputs": [],
   "source": [
    "#saving model for future use\n",
    "model.save(\"model_googlenet_Bnn.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "colab_type": "code",
    "id": "hTVZwuQFWDzs",
    "outputId": "9c5cd795-1d3e-4396-d797-9d9bda66b29b"
   },
   "outputs": [],
   "source": [
    "#Graph represenattaion of loss and accuracy\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.plot(hist.history[\"val_acc\"])\n",
    "plt.title('BNN model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='lower right')\n",
    "plt.figure()\n",
    "print(f\"Training maximum accuracy: {np.max(hist.history['acc']) * 100:.2f} %\")\n",
    "print(f\"Validation maximum accuracy: {np.max(hist.history['val_acc']) * 100:.2f} %\")\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('BNN model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'Validation_loss'], loc='upper right')\n",
    "\n",
    "print(f\"Training model minimum loss: {np.min(hist.history['loss'])}\")\n",
    "print(f\"Validation model minimum loss : {np.min(hist.history['val_loss']) }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Googlenet32bit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
