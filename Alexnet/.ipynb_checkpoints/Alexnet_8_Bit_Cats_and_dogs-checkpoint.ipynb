{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8bit quantized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation,Dropout\n",
    "\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from quantized_ops import quantized_relu as quantize_op\n",
    "#from binary_ops import binary_tanh as binary_tanh_op\n",
    "from quantized_layers import QuantizedDense, QuantizedConv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading customized activation function\n",
    "def quantized_relu(x):\n",
    "    return quantize_op(x,nb=8)\n",
    "\n",
    "#def binary_tanh(x):\n",
    "    #return binary_tanh_op(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = 1.\n",
    "kernel_initializer = 'glorot_uniform'\n",
    "classes = 2\n",
    "use_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=8# to define no of bits required for quantization\n",
    "\n",
    "#loading and preprocessing data from dataset\n",
    "#please change path as per dataset in your system\n",
    "trdata = ImageDataGenerator()\n",
    "\n",
    "traindata = trdata.flow_from_directory(directory=\"/training_set/training_set\",target_size=(227,227))\n",
    "trdata = ImageDataGenerator()\n",
    "\n",
    "testdata = trdata.flow_from_directory(directory=\"/test_set/test_set\",target_size=(227,227))\n",
    "\n",
    "#defining and creating the model as per architecture\n",
    "model = Sequential()\n",
    "# conv1\n",
    "model.add(QuantizedConv2D(96, kernel_size=11, nb=nb, input_shape=(227, 227, 3),strides=4,\n",
    "                       data_format='channels_last', kernel_initializer=kernel_initializer, \n",
    "                       padding='valid', use_bias=use_bias, name='conv1'))\n",
    "model.add(Activation(\"relu\", name='act1'))\n",
    "model.add(MaxPooling2D(pool_size=3,strides=2, name='pool1', data_format='channels_last',padding=\"valid\"))\n",
    "# conv2\n",
    "model.add(QuantizedConv2D(256, kernel_size=5,strides=1, nb=nb, kernel_initializer=kernel_initializer, \n",
    "                       data_format='channels_last',\n",
    "                       padding='same', use_bias=use_bias, name='conv2'))\n",
    "model.add(Activation(quantized_relu, name='act2'))\n",
    "model.add(MaxPooling2D(pool_size=3,strides=2, name='pool2', data_format='channels_last',padding=\"valid\"))\n",
    "# conv3\n",
    "model.add(QuantizedConv2D(384, kernel_size=3,strides=1, nb=nb, kernel_initializer=kernel_initializer,\n",
    "                       data_format='channels_last',\n",
    "                       padding='same', use_bias=use_bias, name='conv3'))\n",
    "model.add(Activation(quantized_relu, name='act3'))\n",
    "# conv4\n",
    "model.add(QuantizedConv2D(384, kernel_size=3,strides=1, nb=nb, kernel_initializer=kernel_initializer,\n",
    "                       data_format='channels_last',\n",
    "                       padding='same', use_bias=use_bias, name='conv4'))\n",
    "model.add(Activation(quantized_relu, name='act4'))\n",
    "#conv5\n",
    "model.add(QuantizedConv2D(256, kernel_size=3,strides=1, nb=nb, kernel_initializer=kernel_initializer,\n",
    "                       data_format='channels_last',\n",
    "                       padding='same', use_bias=use_bias, name='conv5'))\n",
    "model.add(Activation(quantized_relu, name='act5'))\n",
    "model.add(MaxPooling2D(pool_size=3,strides=2, name='pool5', data_format='channels_last',padding=\"valid\"))\n",
    "#Flatten layer\n",
    "model.add(Flatten())\n",
    "# dense layer 1\n",
    "model.add(QuantizedDense(9216, kernel_initializer=kernel_initializer, use_bias=use_bias, name='dense1'))\n",
    "model.add(Activation(quantized_relu, name='act_dense1'))\n",
    "model.add(Dropout(0.5))\n",
    "# dense layer 2\n",
    "model.add(QuantizedDense(4096, kernel_initializer=kernel_initializer, use_bias=use_bias, name='dense2'))\n",
    "model.add(Activation(quantized_relu, name='act_dense2'))\n",
    "#dense layer 3\n",
    "model.add(QuantizedDense(4096, kernel_initializer=kernel_initializer, use_bias=use_bias, name='dense3'))\n",
    "model.add(Activation(quantized_relu, name='act_dense3'))\n",
    "\n",
    "model.add(QuantizedDense(2, kernel_initializer=kernel_initializer, use_bias=use_bias, name='dense4'))\n",
    "model.add(Activation(\"softmax\", name='act_dense4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining Earlystopping callback and saving the best model for future use\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"alexnet_fp_32bit.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#training and validating train and validation data respectively\n",
    "hist = model.fit_generator(steps_per_epoch=2,generator=traindata, validation_data= testdata, \n",
    "                           validation_steps=10,epochs=30,callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model for future use\n",
    "model.save(\"model_alexnet_mnist_8_bit.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph represenattaion of loss and accuracy\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.plot(hist.history[\"val_acc\"])\n",
    "plt.title('8 Bit model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='lower right')\n",
    "plt.figure()\n",
    "print(f\"Training maximum accuracy: {np.max(hist.history['acc']) * 100:.2f} %\")\n",
    "print(f\"Validation maximum accuracy: {np.max(hist.history['val_acc']) * 100:.2f} %\")\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('8 Bit model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'Validation_loss'], loc='upper right')\n",
    "\n",
    "print(f\"Training model minimum loss: {np.min(hist.history['loss'])}\")\n",
    "print(f\"Validation model minimum loss : {np.min(hist.history['val_loss']) }\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
